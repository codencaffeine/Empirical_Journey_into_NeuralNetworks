{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# `The humble MNIST classification problem!`\n",
        "### This hopefully will be a simple way to illustrate how a neural network works. There will be a few assumptions made before we dive into the explanations (for example, familiarity with how an image is represented as a numpy array, etc). The key is to not give up!\n",
        "\n",
        "### The MNIST is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images and our job is to make our model (Neural network) to correctly identity which category each image from the dataset belongs to.\n",
        "\n",
        "\n",
        "## `The following are the steps involved in solving simple problems using Neural networks:`\n",
        "1. Download/Import DataSet \n",
        "2. Split/Load data into `TrainSet` and `TestSet`\n",
        "3. Prepare the data in such a way that its compatible to be fed to our Neural Network (NN)\n",
        "4. Contrusct/Architect a NN\n",
        "5. Compile the NN by using 3 things: `Optimizer` | `Loss` | `Metrics of evaluation`\n",
        "6. Train/Fit the NN to our DataSet\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nfziYYSAP9mV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz_dUuVHP8j5",
        "outputId": "34ea3894-b894-4884-df7d-c4e6d5536fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "The shape of Train Images is: (60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from keras import utils\n",
        "utils.set_random_seed(15)\n",
        "\n",
        "\n",
        "from keras.datasets import mnist                              # Importing the dataset of MNIST from keras\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "                                                              # Here, we use the load_data() function to give us 4 sets of data\n",
        "                                                              # Train images, Train labels are the first 2 sets that are grouped together into a tuple\n",
        "                                                              # Test images and Test labels are the 2 other categories that the load.data() returns\n",
        "                                                              # The shape of the Train images and Test images will be (60000,28,28)\n",
        "                                                              # The shape of the Train and Test labels will be (60000,) since its a scalar\n",
        "\n",
        "# Uncomment the following code to view the shape of each of the sets we discussed above.\n",
        "\n",
        "print(f\"The shape of Train Images is: {train_images.shape}\")\n",
        "# print(f\"The shape of Train Labels is: {train_labels.shape}\")\n",
        "# print(f\"The shape of Test Images is: {test_images.shape}\")\n",
        "# print(f\"The shape of Test Labels is: {test_labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Visualise how the images in this DataSet look!\n",
        "For visualization and plotting, we will use the matplotlib library."
      ],
      "metadata": {
        "id": "tb4lMzKXy4TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt                               # Importing the matplotlib library for visualization\n",
        "\n",
        "digit_image = train_images[15]                                # Choosing the 15th image from our train DataSet to visualize\n",
        "\n",
        "plt.imshow(digit_image, cmap = \"binary\")                      # imshow() method creates a figure of our image using matplotlib, \n",
        "                                                              # and binary is to show in black and white\n",
        "plt.show()                                                    # plt.show() displays the created image."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2KtSHDCbzEjx",
        "outputId": "bad76e7d-965f-43bf-84d3-9f037c767249"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are done with the first 2 steps to solve this problem, which are as follows:\n",
        "1. Download/Import DataSet ✔\n",
        "2. Split/Load data into `TrainSet` and `TestSet` ✔\n",
        "\n",
        "Now moving on to the next step\n",
        "\n"
      ],
      "metadata": {
        "id": "btuZc-8DXLiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Preprocessing the Data!`\n",
        "1. The original shape of the data is (60000, 28, 28), and we change it to (60000, 28*28)\n",
        "2. The original type is uint8, and we change it to float32 for the division part in next step\n",
        "3. We reduce the values of the pixels in the images from the range of (0 to 255) to (0 to 1)"
      ],
      "metadata": {
        "id": "QJCsSGt2gI41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28*28)).astype('float32')\n",
        "                                                              # We change the shape to (60000, 28*28) as expected by our model(NN) and as float32\n",
        "test_images = test_images.reshape((10000, 28*28)).astype('float32')\n",
        "                                                              # We change the shape to (10000, 28*28) as expected by our model(NN) and as float32\n",
        "\n",
        "train_images = train_images/255                               # We reduce the range of pixel values from (0-255) to (0-1)\n",
        "test_images = test_images/255                                 # We reduce the range of pixel values from (0-255) to (0-1)\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical                        # We import the to_categorical that converts integers to binary class matrix.\n",
        "\n",
        "train_labels = to_categorical(train_labels)                   # Converting the integers to a binar class matrix\n",
        "test_labels = to_categorical(test_labels)                     # Converting the integers to a binar class matrix\n"
      ],
      "metadata": {
        "id": "Mg-ft_RUetiI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.serialization import activation\n",
        "from IPython.utils.io import unicode_std_stream\n",
        "from keras import models                                      # Importing models from keras\n",
        "from keras import layers                                      # There are two types of models that keras offers: Sequential API and Functional API\n",
        "                                                              # We will use the sequential one!\n",
        "our_neural_network = models.Sequential(                       # Creating our neural network with a sequential model\n",
        "    [layers.Dense(units= 512, activation= \"relu\", input_shape= (28*28,)),\n",
        "                                                              # Units are the number of neurons in that layer\n",
        "                                                              # activation function is used to induce non-linearity in the network, We use ReLu.\n",
        "                                                              # Input_Shape is the shape of the data we will feed the network and it has to be mentioned.\n",
        "     layers.Dense(units= 256, activation= \"relu\"),\n",
        "     layers.Dense(units= 124, activation= \"relu\"),\n",
        "     layers.Dense(units= 64, activation= \"relu\"),\n",
        "     layers.Dense(units = 10, activation= \"softmax\")          # The last layer will have 10 neurons as we have 10 categories to classify\n",
        "                                                              # The activation function now will be softmax, as it returns the probability of which \n",
        "                                                              # category a particular digit belongs to\n",
        "     \n",
        "    ]\n",
        ")\n",
        "\n",
        "#Now comes the compilation part!\n",
        "\n",
        "our_neural_network.compile(                                   # We use the compile method to configure our model for training\n",
        "    optimizer= \"adam\",                                        # Optimizer is a mechanism by which the model will update itself to become better \n",
        "    loss = \"categorical_crossentropy\",                        # loss is the loss function is the mechanism used to steer the model in the right \n",
        "                                                              # direction to better itself!\n",
        "    metrics= ['accuracy']                                     # A means to judge the performance of the model (example: accuracy)\n",
        ")"
      ],
      "metadata": {
        "id": "kLqRN805RH-h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are done with the first 5 steps to solve this problem, which are as follows:\n",
        "1. Download/Import DataSet ✔\n",
        "2. Split/Load data into `TrainSet` and `TestSet` ✔\n",
        "3. Prepare the data in such a way that its compatible to be fed to our Neural Network (NN) ✔\n",
        "4. Contrusct/Architect a NN ✔\n",
        "5. Compile the NN by using 3 things: `Optimizer` | `Loss` | `Metrics of evaluation` ✔\n",
        "\n",
        "Now its time for us to train/fit our very first neural network! We use the `fit` method to do so."
      ],
      "metadata": {
        "id": "2uttoVfciXNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "our_neural_network.fit(train_images, train_labels, batch_size= 82, epochs= 12)\n",
        "                                                              # Now lets train our NN for 10 epochs and see what happens! \n",
        "                                                              # The fit method needs our train images and train labels, epochs needed and batch size!\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z4DdV2FcYo_",
        "outputId": "6b14777f-7ef2-416f-af43-fbbd66525326"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "732/732 [==============================] - 9s 9ms/step - loss: 0.2259 - accuracy: 0.9313\n",
            "Epoch 2/12\n",
            "732/732 [==============================] - 6s 8ms/step - loss: 0.0869 - accuracy: 0.9739\n",
            "Epoch 3/12\n",
            "732/732 [==============================] - 7s 9ms/step - loss: 0.0615 - accuracy: 0.9806\n",
            "Epoch 4/12\n",
            "732/732 [==============================] - 8s 11ms/step - loss: 0.0459 - accuracy: 0.9859\n",
            "Epoch 5/12\n",
            "732/732 [==============================] - 8s 11ms/step - loss: 0.0377 - accuracy: 0.9875\n",
            "Epoch 6/12\n",
            "732/732 [==============================] - 6s 8ms/step - loss: 0.0286 - accuracy: 0.9908\n",
            "Epoch 7/12\n",
            "732/732 [==============================] - 6s 9ms/step - loss: 0.0265 - accuracy: 0.9915\n",
            "Epoch 8/12\n",
            "732/732 [==============================] - 6s 8ms/step - loss: 0.0234 - accuracy: 0.9926\n",
            "Epoch 9/12\n",
            "732/732 [==============================] - 7s 10ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 10/12\n",
            "732/732 [==============================] - 6s 8ms/step - loss: 0.0194 - accuracy: 0.9938\n",
            "Epoch 11/12\n",
            "732/732 [==============================] - 7s 9ms/step - loss: 0.0164 - accuracy: 0.9948\n",
            "Epoch 12/12\n",
            "732/732 [==============================] - 6s 8ms/step - loss: 0.0166 - accuracy: 0.9948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16fdb4fb80>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Now there was something purposeful in choosing the number of epochs as 12!\n",
        "As you will see, The model achieves an accuracy above 98% in the first few epoch itself(the accuracy will vary with every instance of training, so dont worry if you are getting a different result than mine). After which the accuracy only increases marginally or even fluctuates around a certain percentage. This is an excellent symptom of overfitting! \n",
        "\n",
        "2. `Overfitting`, to put in layman's term, is a condition where your model has learned the representation of your dataset so well, that it does not perform well when it is given any other new data. `It is a condition to be avoided` and there are certain techniques to do so.\n",
        "\n",
        "3. Here, we can use, perhaps the simplest technique when you see overfitting, which is to `simplify your model`, or reduce the complexity of our model. Or, we can `reduce the number of epochs!` \n",
        "\n",
        "4. The neural network that we built maybe has too many layers and is too complex for the humble dataset of MNIST. Try reducing the dense layers in the NN and see what happens. Also, you can try to reduce the number of epochs! I wont explain what method out of these two you must use, rather try it yourself!\n",
        "\n",
        "5. Now we will move on to testing whether our model is any good. This can be done by making the model predict using the **Test DataSet**"
      ],
      "metadata": {
        "id": "SLBEYk4ApdS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = our_neural_network.evaluate(test_images, test_labels)\n",
        "                                                                # The evaluate method to check the performance of our model on test/new data\n",
        "                                                                # which returns us 2 values: loss and accuracy!\n",
        "print(f\"The performance of our model on the test data is as follows : \\nTest loss: {test_loss}\\nTest accuracy:{test_accuracy}\")\n",
        "                                                                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZqi06EDjfd6",
        "outputId": "c76bf6e5-060a-4a42-de4b-d5aa6be88e39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9821\n",
            "The performance of our model on the test data is as follows : \n",
            "Test loss: 0.07897141575813293\n",
            "Test accuracy:0.9821000099182129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, my training accuracy was 99.48% and I got a test accuracy of 98.21%, which isn't too bad, but not great either. So do try the methods to avoid overfitting and see the gap between the training accuracy and the test accuracy diminish!\n",
        "\n",
        "Hope this was a simple tutorial for those who want to directly dive into the empirical journey of NNs and not heavy on theory. \n",
        "\n",
        "***Phir milenge!*** ✨"
      ],
      "metadata": {
        "id": "y8XBKLZkkVF0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ic4Z5Y2CkAP2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
